<!DOCTYPE html>
<html>
<body>
<h1>CSCI 5611 Project 1</h1>
<h1>Ben Moorlach</h1>


<h2>Images</h2>
<figure>
    <img src="singleAgent.png" alt="A single agent navigating a course" width = 500 height = 500>
    <figcaption>A single purple agent navigating a course of yellow obstacles towards the green goal</figcaption>
</figure>

<figure>
    <img src="multipleAgents.png" alt="Multiple agents navigating a course" width = 500 height = 500>
    <figcaption>Multiple purple agents navigating a course of yellow obstacles towards the greeen goal</figcaption>
</figure>




<h2>List of features attempted and description</h2>
<ul>
    <li>Single Agent Navigation
        <ul>
            <li>An agent uses the A* algorithm on a graph created by placing a user-decided number of nodes to navigate to the goal.  I smoothed the look of the agents by navigating to the node that is furthest along the agent's path that is visible</li>
        </ul>
    </li>
    <li>User Senario Editing
        <ul>
            <li>The user starts each simulation by clicking the mouse to place an obstacle.</li>
            <li>The user can make the latest obsticle added larger or smaller by pressing the right or left arrow key</li>
            <li>Once the user is done adding obsticles, they press the space bar, and can click the mouse anywhere to add agents. If they click on an obsticle the agent will not be added</li>
            <li>Once the user is done adding agents, they press the space bar, and can click anywhere to set the goal position for all agents</li>
            <li>The user then presses the space bar again to run the simulation and can press r at anytime to restart</li>
        </ul>
    </li>
    <li>Real Time User Interaction
        <ul>
            <li>At any time during the simulation, the user can click the mouse and change the goal position.  The agents will recalculate the path and navigate to the new goal.</li>
        </ul>
    </li>
    <li>Multiple Agents Planning
        <ul>
            <li>Multiple agents can be added by the user and each will have their own path to the goal</li>
        </ul>
    </li>
    <li>Crowd Simulation
        <ul>
            <li>I chose to use boids as my crowd simulation</li>
            <li>The agents will not collide with one another</li>
            <li>If the agents have no path to the goal, they will continue to move in a boid like fashion</li>
            <li>Once all of the agents have arrived at the goal, they don't like to get too close to each other so will go to the outside of the crowd sourounding the goal.</li>
        </ul>
    </li>
</ul>


<h2>Code</h2>
<p>I modified the original Proj1_Test.pde code to run my simulations, modified PRM.pde to run my path finding, and used Vec2.pde and CollisionLibrary.pde to assist with vector math and collision detection, respectively.</p>
<a href="https://docs.google.com/document/d/1vQI8y8Pl2QVxR8CvqgVDqaTgguhP0uDk6r4x41r0blQ/edit?usp=sharing">Simulation Code</a><br>
<a href="https://docs.google.com/document/d/1Sj3M6JfL6Hio5uke-IVI-p2gfXfLMP_62pAmSPSEG4k/edit?usp=sharing">PRM code</a><br>
<a href="https://docs.google.com/document/d/1a4SgH6X6eDCvVOIOIo8LK7M0cAc4XMQyMkTgajdMaVg/edit?usp=sharing">Vec2 Code</a><br>
<a href="https://docs.google.com/document/d/1RwN78dRCPT8ewyKvKr6wOkPs0Xf-ePXsAg1nTjT2ZLA/edit?usp=sharing">Collision Library code\n</a><br>

<h2>Tools and Libraries</h2>
<p>I did not use many external tools and libraries outside of Processing to display the behavior of my simulations.  I did use the Vec2.pde code to deal with 2-dimensional vectors and the CollisionLibrary.pde to work with collisions.</p>
<h2>Difficulties</h2>
<h3>A*</h3>
<p>Initially, I was having trouble getting the A* algorithm to work.  I knew exatly how the A* algorithm worked, but for what ever reason, it was not performing significantly better than BFS.  The problem turned out to be the way I was storing the calculated heuristics.  When ever I would update my goal position, the heuristic wouldn't update, so the searching would favor the location of the previous goal location</p>
<h3>Fine tuning forces</h3>
<p>Another thing that took me awhile was figuring out how much each force should be valued.  I have multiple forces:<br> The goal force which guides the agents to their next node in the PRM graph <br> The obsticle force which pushed the agents away from obsticles if they get too close <br> The three boids forces, avoidence, cohesion, and allignment.</p>


<h2>Video</h2>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Y9NW_XnbvOk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p>Agents navigating to a path</p><br><br>

<iframe width="560" height="315" src="https://www.youtube.com/embed/iQVaFpbZ4kE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p>Trapped Agents</p>
</body>
</html>